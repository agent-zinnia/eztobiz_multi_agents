from langgraph_sdk import get_client
from langchain_core.messages import HumanMessage
import asyncio
from typing import Dict, Any


class DualAgentSystem:
    """System that coordinates two agents using langgraph_sdk"""
    
    def __init__(self, url: str = "http://127.0.0.1:2024"):
        """Initialize the dual agent system
        
        Args:
            url: URL of the local langgraph server
        """
        self.url = url
        self.client = get_client(url=url)
    
    def _extract_last_ai_message(self, messages: list) -> str:
        """Extract the last AI message from a list of messages
        
        Args:
            messages: List of messages from the agent state
            
        Returns:
            The content of the last AI message, or a fallback message
        """
        # Find the last AI message
        for msg in reversed(messages):
            if hasattr(msg, 'type') and msg.type == "ai":
                return msg.content
            elif isinstance(msg, dict) and msg.get("type") == "ai":
                return msg.get("content", "")
        
        # Fallback: get any message content
        if messages:
            last_msg = messages[-1]
            if hasattr(last_msg, 'content'):
                return last_msg.content
            elif isinstance(last_msg, dict):
                return last_msg.get("content", str(last_msg))
            else:
                return str(last_msg)
        
        return "No result generated"
    
    async def run_first_agent(self, query: str) -> Dict[str, Any]:
        """Run the first agent (math calculation agent) with the given query
        
        Args:
            query: The user's question/request
            
        Returns:
            Dictionary containing the result from the first agent
        """
        try:
            # Create a thread for the first agent
            thread = await self.client.threads.create()
            thread_id = thread["thread_id"]
            
            # Run the first agent (using the graph name from langgraph.json)
            run = await self.client.runs.create(
                thread_id=thread_id,
                assistant_id="math_agent",  # This matches the graph name in langgraph.json
                input={"messages": [HumanMessage(content=query)]}
            )
            
            # Wait for completion
            await self.client.runs.join(thread_id=thread_id, run_id=run["run_id"])
            
            # Get the final state/messages
            state = await self.client.threads.get_state(thread_id=thread_id)
            
            # Extract messages from the state
            messages = state.get("values", {}).get("messages", [])
            last_ai_message = self._extract_last_ai_message(messages)
            
            return {
                "success": True,
                "result": last_ai_message,
                "thread_id": thread_id,
                "run_id": run["run_id"],
                "debug_state": state  # For debugging
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "result": None
            }
    
    async def generate_question_with_question_agent(self, first_agent_result: str) -> str:
        """Use the question agent via langgraph server to generate a question based on the first agent's result
        
        Args:
            first_agent_result: Result from the first agent
            
        Returns:
            Generated question from the question agent
        """
        try:
            # Create a thread for the question agent
            thread = await self.client.threads.create()
            thread_id = thread["thread_id"]
            
            # Run the question agent via server - only pass the first agent's result
            run = await self.client.runs.create(
                thread_id=thread_id,
                assistant_id="question_agent",  # This matches the graph name in langgraph.json
                input={
                    "original_query": "",  # Empty since we only want to use first_agent_result
                    "first_agent_result": first_agent_result,
                    "messages": []
                }
            )
            
            # Wait for completion
            await self.client.runs.join(thread_id=thread_id, run_id=run["run_id"])
            
            # Get the final state/messages
            state = await self.client.threads.get_state(thread_id=thread_id)
            
            # Extract messages from the state
            messages = state.get("values", {}).get("messages", [])
            generated_question = self._extract_last_ai_message(messages)
            
            return generated_question if generated_question != "No result generated" else "No question generated by question agent."
                
        except Exception as e:
            return f"Error in question agent: {str(e)}"
    
    async def answer_generated_question(self, generated_question: str) -> Dict[str, Any]:
        """Run the math agent with the generated question from the question agent
        
        Args:
            generated_question: The question generated by the question agent
            
        Returns:
            Dictionary containing the result from answering the generated question
        """
        try:
            # Create a thread for the math agent
            thread = await self.client.threads.create()
            thread_id = thread["thread_id"]
            
            # Run the math agent with the generated question
            run = await self.client.runs.create(
                thread_id=thread_id,
                assistant_id="math_agent",  # This matches the graph name in langgraph.json
                input={"messages": [HumanMessage(content=generated_question)]}
            )
            
            # Wait for completion
            await self.client.runs.join(thread_id=thread_id, run_id=run["run_id"])
            
            # Get the final state/messages
            state = await self.client.threads.get_state(thread_id=thread_id)
            
            # Extract messages from the state
            messages = state.get("values", {}).get("messages", [])
            answer = self._extract_last_ai_message(messages)
            
            return {
                "success": True,
                "question": generated_question,
                "answer": answer,
                "thread_id": thread_id,
                "run_id": run["run_id"]
            }
            
        except Exception as e:
            return {
                "success": False,
                "question": generated_question,
                "error": str(e),
                "answer": None
            }
    
    async def run_triple_agent_workflow(self, user_query: str) -> Dict[str, Any]:
        """Run the complete triple agent workflow: Math -> Question -> Math
        
        Args:
            user_query: The user's original question
            
        Returns:
            Dictionary containing results from all three steps
        """
        print(f"🔄 Starting triple agent workflow for query: '{user_query}'")
        
        # Step 1: Run the first math agent
        print("📊 Step 1: Running first math agent...")
        first_result = await self.run_first_agent(user_query)
        
        if not first_result["success"]:
            print(f"❌ First math agent failed: {first_result['error']}")
            return {
                "error": f"First math agent failed: {first_result['error']}",
                "step1_math_result": None,
                "step2_generated_question": None,
                "step3_answer_to_question": None
            }
        
        print(f"✅ Step 1 completed. Result: {first_result['result']}")
        
        # Step 2: Run the question agent to generate a question
        print("🤔 Step 2: Running question agent to generate a follow-up question...")
        generated_question = await self.generate_question_with_question_agent(
            first_result["result"]
        )
        
        if generated_question.startswith("Error"):
            print(f"❌ Question agent failed: {generated_question}")
            return {
                "error": f"Question agent failed: {generated_question}",
                "step1_math_result": first_result["result"],
                "step2_generated_question": None,
                "step3_answer_to_question": None
            }
        
        print(f"✅ Step 2 completed. Generated question: {generated_question}")
        
        # Step 3: Run the math agent again with the generated question
        print("🔢 Step 3: Running math agent again to answer the generated question...")
        answer_result = await self.answer_generated_question(generated_question)
        
        if not answer_result["success"]:
            print(f"❌ Second math agent failed: {answer_result['error']}")
            return {
                "error": f"Second math agent failed: {answer_result['error']}",
                "step1_math_result": first_result["result"],
                "step2_generated_question": generated_question,
                "step3_answer_to_question": None
            }
        
        print(f"✅ Step 3 completed. Answer: {answer_result['answer']}")
        print("🎉 Triple agent workflow completed successfully!")
        
        return {
            "original_query": user_query,
            "step1_math_result": first_result["result"],
            "step2_generated_question": generated_question,
            "step3_answer_to_question": answer_result["answer"],
            "workflow_metadata": {
                "step1_thread_id": first_result.get("thread_id"),
                "step1_run_id": first_result.get("run_id"),
                "step3_thread_id": answer_result.get("thread_id"),
                "step3_run_id": answer_result.get("run_id")
            }
        }
    
    async def run_dual_agent_workflow(self, user_query: str) -> Dict[str, Any]:
        """Legacy method - redirects to triple agent workflow for backward compatibility
        
        Args:
            user_query: The user's original question
            
        Returns:
            Dictionary containing results from all agents
        """
        return await self.run_triple_agent_workflow(user_query)


# Convenience function for easy usage
async def run_dual_agents(query: str, server_url: str = "http://127.0.0.1:2024") -> Dict[str, Any]:
    """Convenience function to run the triple agent system
    
    Args:
        query: User's question
        server_url: URL of the langgraph server
        
    Returns:
        Results from all three steps (Math -> Question -> Math)
    """
    system = DualAgentSystem(url=server_url)
    return await system.run_triple_agent_workflow(query)


# Example usage
if __name__ == "__main__":
    async def main():
        # Example query
        query = "What is 15 + 27, and then multiply the result by 3?"
        
        # Run the dual agent system
        result = await run_dual_agents(query)
        
        print("\n" + "="*60)
        print("TRIPLE AGENT SYSTEM RESULTS")
        print("="*60)
        print(f"Original Query: {result['original_query']}")
        print(f"\nStep 1 - Math Agent Result: {result['step1_math_result']}")
        print(f"\nStep 2 - Generated Question: {result['step2_generated_question']}")
        print(f"\nStep 3 - Answer to Question: {result['step3_answer_to_question']}")
        
    # Run the example
    asyncio.run(main())
